---
title: "Udhyam Student Text Analysis Report"
author: "Udhyam Analytics"
date: today
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: true
    theme: cosmo
    embed-resources: true
    fig-width: 8
    fig-height: 5
    page-layout: article
execute:
  warning: false
  message: false
  echo: false
  fig.align: center
jupyter: py312_arm_clean
---

```{=html}
<style>
.quarto-figure {
  max-width: 100%;
  overflow-x: hidden;
}
img, .quarto-figure img {
  max-width: 100% !important;
  height: auto !important;
  display: block;
}
.figure-scroll {
  overflow-x: auto;
}
.figure-scroll .quarto-figure {
  max-width: none;
  overflow-x: visible;
  display: inline-block;
}
.figure-scroll img {
  max-width: none !important;
}
</style>
```

```{python}
#| label: setup
import json
import re
from pathlib import Path
from textwrap import fill
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from matplotlib import rcParams
from matplotlib.lines import Line2D
from matplotlib.patches import Patch

# Set professional theme
sns.set_style("whitegrid")
plt.style.use("seaborn-v0_8-darkgrid")

# Define color palette
COLOR_USER = "#3498DB"
COLOR_AI = "#E67E22"
COLOR_POSITIVE = "#2ECC71"
COLOR_NEUTRAL = "#95A5A6"
COLOR_NEGATIVE = "#E74C3C"
COLOR_PRIMARY = "#2C3E50"

# Configure matplotlib defaults
rcParams['figure.facecolor'] = 'white'
rcParams['axes.facecolor'] = 'white'
rcParams['axes.edgecolor'] = '#E5E7EB'
rcParams['axes.labelcolor'] = COLOR_PRIMARY
rcParams['axes.titlesize'] = 14
rcParams['axes.titleweight'] = 'bold'
rcParams['axes.labelsize'] = 10
rcParams['axes.labelweight'] = 'bold'
rcParams['xtick.color'] = '#34495E'
rcParams['ytick.color'] = '#34495E'
rcParams['xtick.labelsize'] = 9
rcParams['ytick.labelsize'] = 9
rcParams['grid.color'] = '#E5E7EB'
rcParams['grid.alpha'] = 0.6
rcParams['text.color'] = COLOR_PRIMARY
rcParams['figure.dpi'] = 100
rcParams['savefig.dpi'] = 100
rcParams['savefig.bbox'] = 'tight'
rcParams['figure.constrained_layout.use'] = True

def find_project_root() -> Path:
    """Locate repository root regardless of Quarto's working directory."""
    start = Path(__file__).resolve().parent if "__file__" in globals() else Path.cwd()
    for candidate in (start,) + tuple(start.parents):
        if (candidate / "data" / "analysis").exists():
            return candidate
    raise FileNotFoundError("Could not locate project root containing data/analysis directory.")

BASE = find_project_root()

def load_csv(path: str) -> pd.DataFrame:
    fp = BASE / path
    if not fp.exists():
        raise FileNotFoundError(f"Expected file not found: {fp}")
    return pd.read_csv(fp)

datetime_overview_json = BASE / "data/analysis/datetime_overview.json"
if not datetime_overview_json.exists():
    raise FileNotFoundError("datetime_overview.json missing. Run scripts/03_generate_summary.py.")
datetime_overview = json.loads(datetime_overview_json.read_text())

cal_state_by_user = load_csv("data/analysis/cal_state_by_user.csv")
message_stats = load_csv("data/analysis/message_stats.csv")
sentiment_user = load_csv("data/analysis/sentiment_user.csv")
sentiment_ai = load_csv("data/analysis/sentiment_ai.csv")
sentiment_overview = load_csv("data/analysis/sentiment_overview.csv")
topic_keywords = load_csv("data/analysis/topic_keywords.csv")

# Add intent_label column if missing (for backward compatibility)
if 'intent_label' not in topic_keywords.columns:
    # Try to load from topic_examples files as fallback
    try:
        topic_examples_user = load_csv("data/analysis/topic_examples_user.csv")
        topic_examples_assistant = load_csv("data/analysis/topic_examples_assistant.csv")

        # Create a mapping from keywords to intent_label by matching keywords exactly
        label_map = {}
        for df, role in [(topic_examples_user, 'user'), (topic_examples_assistant, 'assistant')]:
            if 'intent_label' in df.columns and 'keywords' in df.columns:
                for idx, row in df.iterrows():
                    # Use keywords as key along with role
                    label_map[(role, str(row['keywords']))] = row['intent_label']

        # Apply the mapping by matching keywords
        def get_intent_label(row):
            key = (row['message_role'], str(row['keywords']))
            return label_map.get(key, f"Topic {row.get('topic_id', '?')}")

        topic_keywords['intent_label'] = topic_keywords.apply(get_intent_label, axis=1)
    except Exception as e:
        # If fallback fails, just use topic_id as label
        topic_keywords['intent_label'] = topic_keywords.apply(
            lambda row: f"Topic {row.get('topic_id', '?')}", axis=1
        )

messages = load_csv("data/cleaned/messages_translated.csv")
messages["datetime"] = pd.to_datetime(messages["datetime"], errors="coerce")
messages = messages.dropna(subset=["datetime"])

messages["date"] = messages["datetime"].dt.date
messages["hour"] = messages["datetime"].dt.hour

user_msgs = messages[["datetime", "date", "hour", "whatsapp_id", "user_msg_en", "cal_state"]].rename(columns={"user_msg_en": "message"})
assistant_msgs = messages[["datetime", "date", "hour", "whatsapp_id", "ai_msg_en"]].rename(columns={"ai_msg_en": "message"})

message_topics_user = load_csv("data/analysis/message_topics_user.csv")
message_topics_assistant = load_csv("data/analysis/message_topics_assistant.csv")

agency_user = pd.read_parquet(BASE / "data/analysis/agency_user.parquet")
agency_assistant = pd.read_parquet(BASE / "data/analysis/agency_assistant.parquet")

for frame, role in ((agency_user, "user"), (agency_assistant, "assistant")):
    if "message_role" not in frame.columns:
        frame["message_role"] = role

AGENCY_POS_THRESHOLD = 0.3
AGENCY_NEG_THRESHOLD = -0.3

agency_messages = pd.concat([agency_user, agency_assistant], ignore_index=True, sort=False)

timeline_daily = (
    user_msgs.groupby("date").size().reset_index(name="messages")
    if not user_msgs.empty else pd.DataFrame(columns=["date", "messages"])
)

timeline_hourly = (
    user_msgs.groupby("hour").size().reset_index(name="messages")
    if not user_msgs.empty else pd.DataFrame(columns=["hour", "messages"])
)

cal_state_counts = (
    cal_state_by_user.groupby("cal_state")["message_count"].sum().reset_index().sort_values("message_count", ascending=False)
    if not cal_state_by_user.empty else pd.DataFrame(columns=["cal_state", "message_count"])
)

def formatted_summary():
    total_msgs = datetime_overview.get("total_messages")
    users = datetime_overview.get("unique_users")
    start = datetime_overview.get("start_datetime")
    end = datetime_overview.get("end_datetime")
    coverage = datetime_overview.get("total_days")
    lines = [
        f"Total messages analysed: {total_msgs:,}" if total_msgs is not None else None,
        f"Unique WhatsApp IDs: {users:,}" if users is not None else None,
        f"Data range: {start} to {end}" if start and end else None,
        f"Coverage: {coverage} days" if coverage is not None else None,
    ]
    return "\n".join(line for line in lines if line)

overview_sentence = formatted_summary()

def sentiment_summary(df: pd.DataFrame, role: str) -> str:
    if df.empty:
        return f"No sentiment records for {role}."
    counts = df["sentiment_label"].value_counts(normalize=True).head(3)
    parts = [f"{label} ({pct*100:.1f}%)" for label, pct in counts.items()]
    return f"{role.capitalize()} messages most often express: " + ", ".join(parts)

sentiment_user_sentence = sentiment_summary(sentiment_user, "user")
sentiment_ai_sentence = sentiment_summary(sentiment_ai, "assistant")

def topic_summary(df: pd.DataFrame, role: str, top_n: int = 5) -> str:
    role_df = df[df["message_role"] == role]
    if role_df.empty:
        return f"No topics were identified for {role}."
    top_rows = role_df.sort_values("message_count", ascending=False).head(top_n)
    fragments = [
        f"Topic {row.topic_id}: {row.keywords} ({row.message_count} msgs)"
        for row in top_rows.itertuples()
    ]
    return "\n".join(fragments)

user_topic_sentence = topic_summary(topic_keywords, "user")
assistant_topic_sentence = topic_summary(topic_keywords, "assistant")

def cal_state_table():
    if cal_state_counts.empty:
        return pd.DataFrame(columns=["cal_state", "message_count"])
    cal_state_counts["share_pct"] = cal_state_counts["message_count"] / cal_state_counts["message_count"].sum() * 100
    return cal_state_counts


def _keyword_variants(keywords: str) -> list[str]:
    """Extract keyword variants including underscore replacements and common inflections."""
    tokens = [token.strip() for token in (keywords or "").split(",") if token.strip()]
    variants = set()
    for token in tokens:
        base = token.lower()
        variants.add(base)
        variants.add(base.replace("_", " "))

        # Add common inflections to catch lemmatization mismatches
        if not base.endswith(('s', 'ed', 'ing', 'tion', 'ment')):
            variants.add(base + "s")
            variants.add(base + "ed")
            variants.add(base + "ing")

        # Remove trailing 'e' before adding -ed/-ing
        if base.endswith('e') and len(base) > 2:
            stem = base[:-1]
            variants.add(stem + "ed")
            variants.add(stem + "ing")

        # Handle -ion/-ment variations
        if base.endswith('e'):
            variants.add(base[:-1] + "ion")
        if not base.endswith('ment'):
            variants.add(base + "ment")

    return sorted([variant for variant in variants if variant], key=len, reverse=True)


def highlight_keywords(text: str, keywords: str) -> str:
    if not isinstance(text, str) or not text.strip():
        return ""
    highlighted = text
    for term in _keyword_variants(keywords):
        # Use word boundaries to match whole words, handle lemmatization variants
        pattern = re.compile(rf"(?i)\b({re.escape(term)})\b")
        highlighted = pattern.sub(r"<mark>\1</mark>", highlighted)
    return highlighted


def sample_topic_examples(assign_df: pd.DataFrame, top_topics: pd.DataFrame, per_topic: int = 3) -> list[dict]:
    examples: list[dict] = []
    for _, topic_row in top_topics.iterrows():
        topic_id = int(topic_row.get("topic_id", topic_row.get("Topic", -1)))
        intent_label = str(topic_row.get("intent_label", f"Topic {topic_id}"))
        keywords = str(topic_row.get("keywords", topic_row.get("Name", "")))
        subset = assign_df[assign_df["topic_id"] == topic_id]
        if "original_message" in subset:
            sample_msgs = subset["original_message"].dropna().astype(str).head(per_topic).tolist()
        else:
            sample_msgs = []
        highlighted = [highlight_keywords(msg, keywords) for msg in sample_msgs if msg]
        examples.append({
            "topic_id": topic_id,
            "intent_label": intent_label,
            "keywords": keywords,
            "examples": highlighted,
        })
    return examples

``` 

# Overview

This report analyzes student-AI interactions from the Udhyam's AI Mentor Buddy. The analysis examines message patterns, sentiment, topics, and level of agency demonstrated through conversations to understand how students engage with the AI assistant.

```{python}
#| output: asis
print(f"{overview_sentence}")
```

## Key Findings

...

---

# Part 1: Message Activity {.tabset}

## 1.1 Daily Message Volume

```{python}
#| label: fig-daily-volume
#| fig-cap: "Daily User Message Volume Over Time"
fig, ax = plt.subplots(figsize=(8, 4.5))
if not timeline_daily.empty:
    sns.lineplot(data=timeline_daily, x="date", y="messages", marker="o",
                 color=COLOR_USER, linewidth=2.5, markersize=8, ax=ax)
    ax.set_title("Daily User Message Volume", fontweight='bold', fontsize=14, color=COLOR_PRIMARY)
    ax.set_xlabel("Date", fontweight='bold', fontsize=10)
    ax.set_ylabel("Number of Messages", fontweight='bold', fontsize=10)
    ax.set_ylim(bottom=0)
    plt.xticks(rotation=45, ha="right")
    ax.grid(True, alpha=0.3)
else:
    ax.text(0.5, 0.5, "No user message activity records",
            ha="center", va="center", fontsize=12, color=COLOR_NEUTRAL)
    ax.set_xticks([])
    ax.set_yticks([])
plt.tight_layout()
plt.show()
```

Daily message volume shows the temporal distribution of student engagement with the AI assistant.

## 1.2 Hourly Distribution

```{python}
#| label: fig-hourly-distribution
#| fig-cap: "Hourly Distribution of User Messages Throughout the Day"
fig, ax = plt.subplots(figsize=(8, 4.5))
if not timeline_hourly.empty:
    sns.barplot(data=timeline_hourly, x="hour", y="messages",
                color=COLOR_USER, alpha=0.8, ax=ax)
    ax.set_title("Hourly Distribution of User Messages",
                 fontweight='bold', fontsize=14, color=COLOR_PRIMARY)
    ax.set_xlabel("Hour of Day", fontweight='bold', fontsize=10)
    ax.set_ylabel("Number of Messages", fontweight='bold', fontsize=10)
    ax.grid(True, alpha=0.3, axis='y')

    # Add value labels on bars
    for container in ax.containers:
        ax.bar_label(container, fontsize=9)
else:
    ax.text(0.5, 0.5, "No hourly data available",
            ha="center", va="center", fontsize=12, color=COLOR_NEUTRAL)
    ax.set_xticks([])
    ax.set_yticks([])
plt.tight_layout()
plt.show()
```

This distribution reveals when students are most active in using the platform throughout the day.

## 1.3 Message Distribution by State

```{python}
#| label: tbl-cal-state
#| tbl-cap: "Table 1.3: Message Distribution Across States with Counts and Percentages"
from IPython.display import display, Markdown

cal_table = cal_state_table()
if not cal_table.empty:
    # Format the table for better display
    cal_display = cal_table.copy()
    cal_display.columns = ['CAL State', 'Message Count', 'Share (%)']
    cal_display['Share (%)'] = cal_display['Share (%)'].round(1)
    display(Markdown(cal_display.to_markdown(index=False)))
else:
    print("No state data available")
```

The table above shows message distribution across Indian states (Haryana, Punjab, MP, etc.), indicating which regions generate the most engagement and where students spend the most time interacting with the AI assistant.

## 1.4 Message Statistics

```{python}
#| label: tbl-message-stats
#| tbl-cap: "Table 1.4: Summary Statistics for Message Activity"
from IPython.display import display, Markdown

if not message_stats.empty:
    display(Markdown(message_stats.to_markdown(index=False)))
else:
    print("No message statistics available")
```

---

# Part 2: Sentiment Analysis {.tabset}

Sentiment analysis examines the emotional tone of messages exchanged between students and the AI assistant. Understanding sentiment helps assess user satisfaction and the quality of AI responses.

## Understanding Sentiment Analysis

**What is being measured?**

Each message exchanged between students and the AI assistant is analyzed for emotional tone and classified into sentiment categories: Positive, Neutral, and Negative. This analysis helps us understand how students feel when interacting with the AI, whether the AI maintains an appropriate and supportive tone, and the overall emotional dynamic of conversations.

<details>
<summary>**Methodology (click to expand)**</summary>

The sentiment analysis pipeline employs transformer-based natural language processing models to assess the emotional content of conversational messages. The process unfolds in the following sequence:

1. **Text preprocessing**: Individual messages undergo cleaning and normalization procedures that preserve emotionally significant elements such as punctuation and capitalization, which often carry meaning in informal communication.

2. **Model inference**: Each preprocessed message is processed through a pre-trained sentiment classification model, typically based on BERT or similar transformer architectures. The model analyzes the text and generates probability scores for each sentiment category, capturing the nuanced language patterns in educational discourse.

3. **Classification**: Messages are assigned to sentiment categories (Positive, Neutral, or Negative) based on the highest probability score produced by the model.

4. **Aggregation and comparison**: Classification results are aggregated and grouped by message role (user versus assistant) to enable comparative analysis of sentiment patterns between students and the AI.

The underlying sentiment model has been fine-tuned on conversational text data to better capture the linguistic patterns specific to educational interactions, including informal language conventions, technical code snippets, and domain-specific terminology commonly found in learning platforms. This targeted training ensures that sentiment classifications accurately reflect the context and intent of messages within the Udhyam platform.

</details>

<details>
<summary>**Technical Details (click to expand)**</summary>

**Specific Models Used:**

This analysis uses the `nlptown/bert-base-multilingual-uncased-sentiment` model from Hugging Face, a BERT-based sentiment classifier with the following characteristics:

- **Architecture**: Base-sized BERT (12 layers, 768 hidden dimensions, ~110 million parameters)
- **Multilingual capability**: Trained to support English, Spanish, Hindi, Punjabi, and Hinglish, making it well-suited for analyzing messages that may contain code-switched or mixed-language content common in educational settings
- **Output format**: Produces 5-point sentiment ratings ("1 star", "2 stars", "3 stars", "4 stars", "5 stars") with confidence scores (0.0-1.0)
- **Token limit**: Messages are truncated to a maximum of 512 tokens to fit the model's input constraints

**Engineering and Processing:**

The sentiment analysis pipeline (`scripts/04_sentiment_analysis.py`) implements the following workflow:

1. **Batch processing**: Messages are processed in batches (default: 16 messages per batch) for computational efficiency. This approach balances memory usage with throughput, allowing the pipeline to scale to thousands of messages while maintaining reasonable processing time.

2. **Separate role-based analysis**: User and assistant messages are analyzed independently, producing separate outputs:
   - User sentiment stored in `sentiment_user.csv`
   - Assistant sentiment stored in `sentiment_ai.csv`
   - This separation enables direct comparison of emotional tone between participants

3. **Output schema**: For each message, the pipeline captures:
   - `sentiment_label`: The raw model output (e.g., "4 stars")
   - `sentiment_score`: The model's confidence in this classification (0.0-1.0)
   - `sentiment_stars`: A normalized numeric rating (1-5 scale) extracted from the label

4. **Aggregation and statistics**: Beyond per-message classification, the pipeline computes aggregate statistics:
   - Distribution of sentiments across each role
   - Mean and median sentiment scores
   - Sentiment label frequency counts
   - These summaries are stored in `sentiment_overview.csv` for quick reference

**Model Configuration:**

The model is used with default Hugging Face `pipeline` parameters:
- `truncation=True`: Longer messages are automatically truncated to 512 tokens
- No custom fine-tuning is applied; the model uses its pre-trained weights as distributed by Hugging Face
- The multilingual nature of the base model means it gracefully handles English, mixed-language, and code-containing messages without requiring language-specific preprocessing

**Data Flow in Pipeline:**

Sentiment analysis is the fourth step in the complete analysis pipeline:
1. Load and clean data
2. Translate messages to English (if needed)
3. Generate summary statistics
4. **→ Sentiment analysis** (this step)
5. Topic modeling
6. Agency scoring
7. Generate HTML report

Output files are stored in `data/analysis/` and are consumed by subsequent pipeline steps and the final report visualization.

</details>

## 2.1 Sentiment Comparison

```{python}
#| label: fig-sentiment-comparison
#| fig-cap: "Sentiment Distribution Comparison Between User and AI Messages"

# Create sentiment_counts for visualization
sentiment_long = pd.concat([
    sentiment_user.assign(role="user"),
    sentiment_ai.assign(role="assistant"),
], ignore_index=True, sort=False)

sentiment_counts = (
    sentiment_long.groupby(["role", "sentiment_label"]).size().reset_index(name="messages")
)

fig, ax = plt.subplots(figsize=(8, 4.5))
if not sentiment_counts.empty:
    # Map sentiment labels to colors
    sentiment_colors = {
        'Positive': COLOR_POSITIVE,
        'Neutral': COLOR_NEUTRAL,
        'Negative': COLOR_NEGATIVE,
        'positive': COLOR_POSITIVE,
        'neutral': COLOR_NEUTRAL,
        'negative': COLOR_NEGATIVE
    }

    # Prepare data for plotting
    plot_data = sentiment_counts.copy()
    plot_data['role'] = plot_data['role'].str.capitalize()

    # Create grouped bar chart
    x = np.arange(len(plot_data['sentiment_label'].unique()))
    width = 0.35
    user_data = plot_data[plot_data['role'] == 'User']
    ai_data = plot_data[plot_data['role'] == 'Assistant']

    ax.bar(x - width/2, user_data['messages'], width, label='User',
           color=COLOR_USER, alpha=0.8)
    ax.bar(x + width/2, ai_data['messages'], width, label='Assistant',
           color=COLOR_AI, alpha=0.8)

    ax.set_title("Sentiment Distribution by Role",
                 fontweight='bold', fontsize=14, color=COLOR_PRIMARY)
    ax.set_xlabel("Sentiment", fontweight='bold', fontsize=10)
    ax.set_ylabel("Number of Messages", fontweight='bold', fontsize=10)
    ax.set_xticks(x)
    ax.set_xticklabels(user_data['sentiment_label'].str.capitalize())
    ax.legend(title='Role', fontsize=10, title_fontsize=10)
    ax.grid(True, alpha=0.3, axis='y')

    # Add value labels
    for container in ax.containers:
        ax.bar_label(container, fontsize=9)
else:
    ax.text(0.5, 0.5, "No sentiment records available",
            ha="center", va="center", fontsize=12, color=COLOR_NEUTRAL)
    ax.set_xticks([])
    ax.set_yticks([])
plt.tight_layout()
plt.show()
```

This comparison reveals whether users and the AI assistant maintain different emotional tones during interactions.

## 2.2 Overall Sentiment Summary

```{python}
#| label: tbl-sentiment-overview
#| tbl-cap: "Table 3.2: Overall Sentiment Statistics"
from IPython.display import display, Markdown

if not sentiment_overview.empty:
    display(Markdown(sentiment_overview.to_markdown(index=False)))
else:
    print("No sentiment overview data available")
```

---

# Part 3: Topic Modeling {.tabset}

Topic modeling is a natural language processing technique that identifies the main themes and subjects discussed in conversations. This analysis reveals what students talk about most frequently and how the AI responds, providing insights into student concerns and the AI's pedagogical coverage.

## Understanding Topic Modeling

**What is topic modeling?**

Topic modeling is an unsupervised machine learning approach that automatically discovers latent themes and patterns in textual data without requiring pre-labeled training examples. Each identified topic is represented by multiple dimensions including the most characteristic words (keywords), the frequency of topic occurrence (message count), and the message source (whether the topic appears in user or AI messages). This analytical approach enables us to identify common student questions, recognize recurring concerns, and understand the AI's response patterns across different subject areas.

<details>
<summary>**Methodology: How topics are discovered (click to expand)**</summary>

The topic modeling pipeline employs BERTopic, a modern topic modeling framework that combines transformer-based embeddings with sophisticated clustering and dimensionality reduction algorithms. The complete process unfolds through the following sequential steps:

1. **Text embedding**: Each message in the dataset is converted into a high-dimensional semantic vector representation using sentence transformers (SBERT - Sentence-BERT). These dense embeddings capture the contextual and semantic meaning of the text rather than relying solely on keyword frequency or bag-of-words representations, enabling the model to understand subtle meaning even in short conversational exchanges.

2. **Dimensionality reduction**: The high-dimensional embedding space is projected into a lower-dimensional representation using UMAP (Uniform Manifold Approximation and Projection). This algorithm preserves the local and global semantic relationships between messages while reducing computational complexity, making the data more suitable for clustering algorithms while maintaining the meaningful structure of the embedding space.

3. **Clustering**: Semantically similar messages are grouped together into coherent clusters using HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise). Unlike traditional methods such as Latent Dirichlet Allocation (LDA) that require researchers to pre-specify the number of topics, HDBSCAN automatically determines the optimal number of topics based on the density structure of the embedding space, resulting in more natural topic divisions.

4. **Keyword extraction**: For each identified cluster, c-TF-IDF (class-based Term Frequency-Inverse Document Frequency) is applied to extract the most representative and distinctive keywords. This algorithm identifies words that are statistically frequent within a particular topic while remaining relatively rare in other topics, ensuring that extracted keywords are genuinely representative of each topic's content.

5. **Topic refinement (optional)**: When enabled, the raw keyword lists and sample messages from each topic can be processed through OpenAI's GPT models (such as gpt-4o-mini) to generate human-readable semantic topic labels. This optional refinement step transforms statistical keyword lists into natural language descriptions that capture the broader thematic essence of each cluster, making the results more interpretable to non-technical stakeholders.

6. **Role-based separation**: The complete topic modeling workflow is executed separately for user messages and assistant messages, enabling contrastive analysis of conversation dynamics from both participant perspectives and revealing whether the AI's topic coverage aligns with or complements student interests.

This modern approach yields more coherent and interpretable topics compared to traditional statistical methods, particularly when analyzing conversational messages where context, nuance, and semantic meaning are crucial for accurate interpretation.

**How to interpret OpenAI-refined topics:**

When OpenAI labeling is enabled, the topic labels you see are **not** raw statistical keywords. Instead, they are natural language interpretations generated by a large language model (GPT) based on:

- The initial keyword list from c-TF-IDF
- Sample messages from the topic cluster
- Context about the domain and conversation type

**What this means for interpretation:**

- **More readable**: Topics appear as coherent phrases rather than disconnected keywords (e.g., "Business model validation strategies" instead of "business, model, validate, customer, market")
- **Higher-level abstraction**: The LLM synthesizes the underlying theme rather than just listing common terms
- **Consistency**: Using a fixed temperature ensures deterministic, consistent labeling across runs
- **Trade-offs**: While more interpretable, OpenAI labels may occasionally oversimplify or miss nuances present in the raw keywords. For critical analysis, review both the OpenAI label and the underlying keyword distribution

**When OpenAI refinement is NOT used**, you'll see raw keyword lists extracted via c-TF-IDF, which represent the most statistically distinctive terms for each topic. These are more granular but require more manual interpretation to understand the broader theme.

</details>

<details>
<summary>**Technical Details (click to expand)**</summary>

**Embedding Model:**

The pipeline uses `all-mpnet-base-v2`, a SentenceTransformer model optimized for semantic similarity matching across diverse text types. This multilingual model is well-suited for capturing the semantic relationships in educational discourse, including mixed-language content and technical terminology.

**BERTopic Configuration:**

The topic modeling uses BERTopic with the following component configuration:

- **Minimum topic size**: 15 messages (topics must contain at least 15 messages to be retained)
- **Calculate probabilities**: False (faster computation; topics are hard-assigned rather than probabilistic)
- **Seeded guidance**: Enabled by default with predefined topic seeds (e.g., "Registration", "Deadlines", "Submission", "Business Ideas", "Translation Help", "Teacher Support") to improve topic coherence

**UMAP Parameters (Dimensionality Reduction):**

```
n_neighbors: 30          # Balance between local and global structure preservation
n_components: 5          # Reduced dimensionality for clustering
min_dist: 0.1            # Tighter cluster spacing in reduced space
metric: cosine           # Distance metric optimized for text embeddings
random_state: 42         # Reproducibility
```

**HDBSCAN Parameters (Clustering):**

```
min_cluster_size: 15     # Same as min_topic_size for consistency
min_samples: 5           # Noise point sensitivity
metric: euclidean        # Distance in reduced space
cluster_selection_method: eom  # Excess of Mass (robust for varied density clusters)
cluster_selection_epsilon: 0.0 # No automatic cluster merging
prediction_data: True    # Enable probabilistic assignment
```

**CountVectorizer Parameters (Keyword Extraction):**

```
ngram_range: (1, 2)      # Include both unigrams and bigrams
min_df: 3                # Word must appear in at least 3 documents
max_df: 0.65             # Word must appear in at most 65% of documents (removes too-common words)
stop_words: Custom set   # Language-appropriate stop words
```

**OpenAI Topic Labeling:**

- **Status**: Enabled by default
- **Model**: `gpt-4o-mini` (configurable via environment variable)
- **Temperature**: 0.05 (low randomness for deterministic labeling)
- **Requires**: `OPENAI_API_KEY` environment variable

OpenAI labeling takes the extracted keywords and sample messages from each topic cluster and generates concise, human-readable semantic labels that capture the thematic essence of the cluster.

**Processing Workflow:**

- User and assistant messages are analyzed separately, generating independent topic models for each role
- Message filtering: Only messages with at least 4 tokens after cleaning are included
- Topic similarity merging: Topics with cosine similarity ≥ 0.95 are automatically merged (up to 2 merges per role)
- Output includes: topic metadata, per-message topic assignments, representative keywords, and example messages

**Output Files Generated:**

- `topic_keywords.csv` - Keywords and metadata for each topic (by role)
- `message_topics_user.csv` / `message_topics_assistant.csv` - Per-message topic assignments
- `topic_examples_user.csv` / `topic_examples_assistant.csv` - Sample messages representing each topic

</details>

## 3.1 User Message Topics

::: {.figure-scroll}
```{python}
#| label: fig-user-topics
#| fig-cap: "Top 15 Topics in User Messages"
fig, ax = plt.subplots(figsize=(12, 10))
if not topic_keywords.empty:
    # Get top 15 topics for user messages
    user_topics = topic_keywords[topic_keywords['message_role'] == 'user'].sort_values('message_count', ascending=False).head(15)

    if not user_topics.empty:
        # Sort by message count for better visualization
        user_topics = user_topics.sort_values('message_count', ascending=True)

        # Create horizontal bar chart
        y_pos = np.arange(len(user_topics))
        bars = ax.barh(y_pos, user_topics['message_count'], color=COLOR_USER, alpha=0.8)
        ax.set_yticks(y_pos)
        # Use intent_label if available, otherwise fall back to keywords
        labels = user_topics['intent_label'] if 'intent_label' in user_topics.columns else user_topics['keywords']
        ax.set_yticklabels(labels, fontsize=9)
        ax.set_title("Top Topics in User Messages",
                     fontweight='bold', fontsize=14, color=COLOR_PRIMARY)
        ax.set_xlabel("Number of Messages", fontweight='bold', fontsize=10)
        ax.set_ylabel("Topic", fontweight='bold', fontsize=10)
        ax.grid(True, alpha=0.3, axis='x')

        # Add value labels
        for i, (idx, row) in enumerate(user_topics.iterrows()):
            ax.text(row['message_count'] + max(user_topics['message_count']) * 0.01,
                    i, f"{row['message_count']:,}",
                    va='center', fontsize=8)
    else:
        ax.text(0.5, 0.5, "No user topics identified",
                ha="center", va="center", fontsize=12, color=COLOR_NEUTRAL)
        ax.set_xticks([])
        ax.set_yticks([])
else:
    ax.text(0.5, 0.5, "Topic modeling did not return any clusters",
            ha="center", va="center", fontsize=12, color=COLOR_NEUTRAL)
    ax.set_xticks([])
    ax.set_yticks([])
plt.tight_layout()
plt.show()
```
:::

The user topic visualization reveals what students are asking about and discussing most frequently. These topics represent the primary concerns, questions, and areas where students seek assistance from the AI.

## 3.2 AI Message Topics

::: {.figure-scroll}
```{python}
#| label: fig-ai-topics
#| fig-cap: "Top 15 Topics in AI Messages"
fig, ax = plt.subplots(figsize=(12, 10))
if not topic_keywords.empty:
    # Get top 15 topics for AI messages
    ai_topics = topic_keywords[topic_keywords['message_role'] == 'assistant'].sort_values('message_count', ascending=False).head(15)

    if not ai_topics.empty:
        # Sort by message count for better visualization
        ai_topics = ai_topics.sort_values('message_count', ascending=True)

        # Create horizontal bar chart
        y_pos = np.arange(len(ai_topics))
        bars = ax.barh(y_pos, ai_topics['message_count'], color=COLOR_AI, alpha=0.8)
        ax.set_yticks(y_pos)
        # Use intent_label if available, otherwise fall back to keywords
        labels = ai_topics['intent_label'] if 'intent_label' in ai_topics.columns else ai_topics['keywords']
        ax.set_yticklabels(labels, fontsize=9)
        ax.set_title("Top Topics in AI Messages",
                     fontweight='bold', fontsize=14, color=COLOR_PRIMARY)
        ax.set_xlabel("Number of Messages", fontweight='bold', fontsize=10)
        ax.set_ylabel("Topic", fontweight='bold', fontsize=10)
        ax.grid(True, alpha=0.3, axis='x')

        # Add value labels
        for i, (idx, row) in enumerate(ai_topics.iterrows()):
            ax.text(row['message_count'] + max(ai_topics['message_count']) * 0.01,
                    i, f"{row['message_count']:,}",
                    va='center', fontsize=8)
    else:
        ax.text(0.5, 0.5, "No AI topics identified",
                ha="center", va="center", fontsize=12, color=COLOR_NEUTRAL)
        ax.set_xticks([])
        ax.set_yticks([])
else:
    ax.text(0.5, 0.5, "Topic modeling did not return any clusters",
            ha="center", va="center", fontsize=12, color=COLOR_NEUTRAL)
    ax.set_xticks([])
    ax.set_yticks([])
plt.tight_layout()
plt.show()
```
:::

The AI topic visualization shows the main themes in the assistant's responses. These topics reflect how the AI is addressing student needs and what types of support it provides most frequently.

## 3.3 Interpreting Topic Patterns

To ground the topic labels and provide concrete validation of the topic clusters, the tables below display real message excerpts with topic keywords highlighted. This qualitative approach makes abstract topic interpretations tangible by showing the actual language patterns and phrasing that define each cluster. The highlighted keywords demonstrate how BERTopic identifies thematic coherence within clusters of student and assistant messages.

**Notes on topic example interpretation:**

- Keyword highlights are derived from each topic's extracted keyword list. Since messages undergo lemmatization during preprocessing to normalize word variations, the highlighted forms may include closely related grammatical variants (e.g., "run," "running," "runs" are all recognized as variants of the same root concept).
- Example messages are drawn directly from the translated message corpus (the English text), providing an authentic view of how students and the AI actually phrase their contributions within each identified topic cluster.
- This qualitative grounding is essential for validating that the statistical clustering results align with human interpretation of topic coherence and semantic similarity.

### User topic examples

```{python}
#| output: asis

def _escape_markdown(text: str) -> str:
    """Escape characters that break markdown tables."""
    if not isinstance(text, str):
        text = str(text)
    return text.replace("|", "\\|").replace("\n", " ")

def _render_topic_table(rows) -> str:
    header = [
        '::: {.tbl-colwidths="[0.15,0.20,0.65]"}',
        '| Topic | Keywords | Example messages |',
        '|:------|:---------|:------------------|',
    ]
    body = []
    for row in rows:
        topic_display = f"**{_escape_markdown(row['topic_id'])}: {_escape_markdown(row['intent_label'])}**"
        keywords_display = f"*{_escape_markdown(row['keywords'])}*"
        example_lines = "<br>".join(f"&bull; {_escape_markdown(example)}" for example in row['examples'])
        body.append(f"| {topic_display} | {keywords_display} | {example_lines} |")
    footer = [':::']
    return "\n".join(header + body + footer)

if not topic_keywords.empty and not message_topics_user.empty:
    top_user = (
        topic_keywords[topic_keywords['message_role'] == 'user']
        .sort_values('message_count', ascending=False)
        .head(15)
    )
    rows = sample_topic_examples(message_topics_user, top_user, per_topic=3)
    table_md = _render_topic_table(rows)
    output = [
        "<details>",
        "<summary>Show user topic examples</summary>",
        "",
        table_md,
        "",
        "</details>",
    ]
    print("\n".join(output))
else:
    print("No user topic examples available.")
```

### AI topic examples

```{python}
#| output: asis

if not topic_keywords.empty and not message_topics_assistant.empty:
    top_ai = (
        topic_keywords[topic_keywords['message_role'] == 'assistant']
        .sort_values('message_count', ascending=False)
        .head(15)
    )
    rows = sample_topic_examples(message_topics_assistant, top_ai, per_topic=3)
    table_md = _render_topic_table(rows)
    output = [
        "<details>",
        "<summary>Show AI topic examples</summary>",
        "",
        table_md,
        "",
        "</details>",
    ]
    print("\n".join(output))
else:
    print("No AI topic examples available.")
```

---

# Part 4: Agency Scoring {.tabset}

Agency analysis examines how students and the AI frame their contributions during conversations. Unlike topic modeling which focuses on *what* is being discussed, agency analysis captures *how* participants express themselves—whether they adopt proactive, agentic language or more passive, low-agency communication patterns. This distinction reveals important aspects of student engagement and the AI's pedagogical approach.

## Understanding Agency Scoring

**What is agency in conversations?**

Agency refers to the degree to which participants express themselves as active agents taking initiative, making decisions, and driving action, as opposed to passive recipients of information or instruction. In the context of student-AI interactions, high agency messages typically include:

- **Student agency**: Taking initiative in problem-solving, asking clarifying questions, proposing solutions, expressing intentions and goals
- **AI agency**: Offering guidance that empowers student decision-making, encouraging exploration and experimentation, facilitating student ownership of learning

Low-agency messages, by contrast, tend to involve passive reception, implicit requests, or statements of helplessness or dependence.

<details>
<summary>**Methodology: How agency is scored (click to expand)**</summary>

**How BERTAgent is Created (The 7 Stages)**

1. **Assemble Seed Words (ASD)**  
   Collect agency-related terms from prior dictionaries/lists (e.g., Pietraszkiewicz, Nicolas, LIWC-derived composites), then expand stems to word forms (**xASD**). 

2. **Build a Lexicographic Dataset (ALD)**  
   Use the xASD words to pull synsets (definitions, lemmas, usage examples) from Open English WordNet—so the model sees words with context.  

3. **Human-Rate Agency**  
   Crowd workers rate each synset/example on a 7-point low↔high agency scale; those ratings become training targets.  

4. **Fine-Tune Transformer LMs (Regression)**  
   Train BERT/RoBERTa to predict the human agency score from text snippets; compare several dataset constructions (FT0–FT3).  

5. **Create a Gold-Standard Set (GSD)**  
   Curate 300 sentences (balanced low/none/high agency) from prompted writings.  

6. **Human-Rate the GSD**  
   Get ~30 ratings per sentence to obtain highly reliable ground truth.  

7. **Select the Best Model**  
   Pick the model with the lowest RMSE on the held-out GSD (RoBERTa on FT3; further improved after a negation-focused re-fine-tune **rFT3**).

**Notes:**  
They also add antonym- and negation-based data augmentation and later re-fine-tune (**rFT3**) to better handle nuanced negations, which lowers RMSE further.  

**How BERTAgent Produces Individual Agent Scores**

BERTAgent is packaged in Python. You pass sentences; it returns an **agency score per sentence** in the range **−1 to 1**.  
Because of token limits, it’s sentence-first; you then aggregate to the unit you care about (message, person, day, etc.).

**Clean Pipeline**

1. **Prepare per-person corpora**  
   Group all texts by individual (e.g., teacher/user).

2. **Light clean-up**  
   Normalize whitespace and sentence-split; keep punctuation (negation and emphasis matter).

3. **Score sentences**  
   Run BERTAgent on each sentence → one score in −1 to 1.  

4. **Aggregate to messages**  
   Combine sentence scores per message.  
   - *Mean*: overall level  
   - *Max*: bursts of strong agency  
   - *Min*: lowest-agency clause  

5. **Aggregate to the individual**  
   Choose method(s):  
   - Average or median agency across messages  
   - Share of high/low agency messages
   - Time-weighted indices (recent messages count more)  
   - Contextual slices (topic, channel, daypart)

6. **Stability checks**  
   Require a minimum number of messages; bootstrap confidence intervals for person-level scores.

7. **Audit edge cases**  
   Negations and sarcasm are hard—spot-check samples and consider the **rFT3** model for improved negation handling.

</details>

<details>
<summary>**Technical Details (click to expand)**</summary>

**Agency Scoring Model:**

The analysis uses `EnchantedStardust/bertagent-best`, a Hugging Face model specifically trained for agency detection in conversational text. Key characteristics:

- **Model type**: AutoModelForSequenceClassification (transformer-based)
- **Output**: Continuous numerical scores (not discrete classifications)
- **Architecture**: Single-output regression model trained on agency-annotated conversational data
- **Weight format**: Safetensors (for security and compatibility)
- **Tokenization**: Case-insensitive, with standard padding and attention masking

**Scoring Process:**

1. **Input preprocessing**: Messages are normalized by reducing multiple whitespaces to single spaces. Text is truncated to a maximum of 256 whitespace-delimited tokens to fit model constraints.

2. **Batch inference**: Messages are processed in batches (default: 32) for computational efficiency. The model generates raw logits which are transformed into continuous agency scores.

3. **Score generation**:
   - Positive scores (0 to +1): Agentic language, initiative, proactive decisions
   - Negative scores (-1 to 0): Passive language, dependence, low agency
   - Near-zero scores: Minimal agency information (neutral acknowledgments, brief responses)

4. **Threshold classification**: Based on thresholds, each score is classified as:
   - **High agency**: score ≥ 0.3
   - **Low agency**: score ≤ -0.3
   - **Neutral agency**: -0.3 < score < 0.3

**Configuration Parameters:**

- **Positive threshold**: 0.3 (configurable)
- **Negative threshold**: -0.3 (configurable)
- **Batch size**: 32 messages per batch (configurable)
- **Max tokens**: 256 whitespace-delimited tokens (configurable)
- **Device**: Automatic GPU detection with CUDA support; falls back to CPU if unavailable
- **Random seed**: 42 (for reproducibility)

**Computation:**

- GPU acceleration with CUDA memory cache clearing after each batch to prevent memory leaks
- Automatic fallback to CPU inference if CUDA is unavailable
- Robust error handling for model loading (safetensors format prevents pickle vulnerabilities)

**Output Schema:**

Each message receives the following fields:

```
- message_id: Unique identifier per message
- agency_score: Continuous score (-1 to +1)
- is_high: Boolean indicating high agency (score ≥ 0.3)
- is_low: Boolean indicating low agency (score ≤ -0.3)
- message_role: "user" or "assistant"
- (original text fields preserved)
```

**Role-Based Analysis:**

- User and assistant messages are scored independently, generating separate output files
- `data/analysis/agency_user.parquet` - User message agency scores
- `data/analysis/agency_assistant.parquet` - Assistant message agency scores
- Files also preserve original datetime and WhatsApp ID if present in input

**Pipeline Integration:**

Agency scoring is the sixth step in the complete analysis pipeline:
1. Load and clean data
2. Translate messages to English
3. Generate summary statistics
4. Sentiment analysis
5. Topic modeling
6. **→ Agency scoring** (this step)
7. Generate HTML report

The agency scores are aggregated into summary statistics and visualized in the report to show comparative agency patterns between students and the AI assistant.

</details>

## 4.1 Agency Scoring Summary

```{python}
#| label: tbl-agency-summary
#| tbl-cap: "Table 4.1: Agency Scoring Statistics by Message Role"
if not agency_messages.empty:
    def pct(series: pd.Series) -> float:
        valid = series.dropna()
        if valid.empty:
            return np.nan
        return float(valid.astype(int).mean() * 100)

    summary = (
        agency_messages.groupby("message_role")
        .agg(
            total_messages=("message_id", "count"),
            scored_messages=("agency_score", lambda x: int(x.notna().sum())),
            mean_agency=("agency_score", lambda x: x.mean()),
            median_agency=("agency_score", lambda x: x.median()),
            pct_high=("is_high", pct),
            pct_low=("is_low", pct),
        )
        .reset_index()
        .replace({"message_role": {"user": "User", "assistant": "Assistant"}})
    )
    summary["mean_agency"] = summary["mean_agency"].round(3)
    summary["median_agency"] = summary["median_agency"].round(3)
    summary["pct_high"] = summary["pct_high"].round(1)
    summary["pct_low"] = summary["pct_low"].round(1)
    display(summary.rename(columns={
        "message_role": "Role",
        "total_messages": "Messages",
        "scored_messages": "Non-empty",
        "mean_agency": "Mean agency",
        "median_agency": "Median agency",
        "pct_high": f"% ≥ {AGENCY_POS_THRESHOLD}",
        "pct_low": f"% ≤ {AGENCY_NEG_THRESHOLD}",
    }))
else:
    print("No agency scores available. Run scripts/06_agency_scoring.py.")
```

## 4.2 Agency Distribution

```{python}
#| label: fig-agency-distribution
#| fig-cap: "Distribution of Agency Scores by Message Role"
fig, ax = plt.subplots(figsize=(8, 5))
score_df = agency_messages.dropna(subset=["agency_score"])
if not score_df.empty:
    palette = {"user": COLOR_USER, "assistant": COLOR_AI}
    sns.histplot(
        data=score_df,
        x="agency_score",
        hue="message_role",
        bins=40,
        element="step",
        stat="count",
        palette=palette,
        ax=ax,
    )
    ax.axvline(AGENCY_POS_THRESHOLD, color=COLOR_POSITIVE, linestyle="--", linewidth=1.5, label="High-agency threshold")
    ax.axvline(AGENCY_NEG_THRESHOLD, color=COLOR_NEGATIVE, linestyle="--", linewidth=1.5, label="Low-agency threshold")
    ax.set_xlabel("Agency score", fontweight="bold")
    ax.set_ylabel("Messages", fontweight="bold")
    legend_handles = [
        Patch(facecolor="none", edgecolor=COLOR_USER, linewidth=2, label="User"),
        Patch(facecolor="none", edgecolor=COLOR_AI, linewidth=2, label="Assistant"),
        Line2D([], [], color=COLOR_POSITIVE, linestyle="--", linewidth=1.5, label=f"High threshold ({AGENCY_POS_THRESHOLD})"),
        Line2D([], [], color=COLOR_NEGATIVE, linestyle="--", linewidth=1.5, label=f"Low threshold ({AGENCY_NEG_THRESHOLD})"),
    ]
    ax.legend(handles=legend_handles, frameon=False)
else:
    ax.text(0.5, 0.5, "No agency scores available", ha="center", va="center", fontsize=12)
    ax.set_xticks([])
    ax.set_yticks([])
plt.tight_layout()
plt.show()
```

## 4.3 Qualitative Examples

The following tables show messages with the highest and lowest agency scores for each participant type, providing concrete illustrations of what high-agency, low-agency, and neutral-agency communication looks like in the context of student-AI interactions:

```{python}
#| label: tbl-agency-user-high
#| tbl-cap: "Top High-Agency User Messages"
#| output: asis
from IPython.display import display, Markdown

if not agency_messages.empty:
    subset = agency_messages[agency_messages["message_role"] == "user"].copy()
    subset = subset.dropna(subset=["agency_score"])
    text_column = "text_translated" if "text_translated" in subset.columns else "text_original"

    top_pos = (
        subset.nlargest(5, "agency_score")
        .loc[:, ["message_id", "agency_score", text_column]]
        .rename(columns={text_column: "message"})
        .copy()
    )

    if not top_pos.empty:
        # Escape special characters that break markdown tables
        top_pos["message"] = top_pos["message"].apply(
            lambda x: str(x).replace("|", "\\|").replace("\n", " ") if pd.notna(x) else ""
        )
        display(Markdown(top_pos.reset_index(drop=True).to_markdown()))
else:
    print("No agency scores available.")
```

```{python}
#| label: tbl-agency-user-low
#| tbl-cap: "Lowest Agency User Messages"
#| output: asis

if not agency_messages.empty:
    subset = agency_messages[agency_messages["message_role"] == "user"].copy()
    subset = subset.dropna(subset=["agency_score"])
    text_column = "text_translated" if "text_translated" in subset.columns else "text_original"

    top_neg = (
        subset.nsmallest(5, "agency_score")
        .loc[:, ["message_id", "agency_score", text_column]]
        .rename(columns={text_column: "message"})
        .copy()
    )

    if not top_neg.empty:
        # Escape special characters that break markdown tables
        top_neg["message"] = top_neg["message"].apply(
            lambda x: str(x).replace("|", "\\|").replace("\n", " ") if pd.notna(x) else ""
        )
        display(Markdown(top_neg.reset_index(drop=True).to_markdown()))
else:
    print("No agency scores available.")
```

```{python}
#| label: tbl-agency-user-neutral
#| tbl-cap: "Neutral Agency User Messages"
#| output: asis

if not agency_messages.empty:
    subset = agency_messages[agency_messages["message_role"] == "user"].copy()
    subset = subset.dropna(subset=["agency_score"])
    text_column = "text_translated" if "text_translated" in subset.columns else "text_original"

    neutral_cutoff = 0.15
    neutral_subset = subset[(subset["agency_score"].abs() <= neutral_cutoff)]
    if len(neutral_subset) > 0:
        neutral = neutral_subset.sample(min(5, len(neutral_subset)), random_state=42)
        neutral = neutral.loc[:, ["message_id", "agency_score", text_column]].rename(columns={text_column: "message"}).copy()
        # Escape special characters that break markdown tables
        neutral["message"] = neutral["message"].apply(
            lambda x: str(x).replace("|", "\\|").replace("\n", " ") if pd.notna(x) else ""
        )
        display(Markdown(neutral.reset_index(drop=True).to_markdown()))
    else:
        print("No neutral agency user messages found.")
else:
    print("No agency scores available.")
```

```{python}
#| label: tbl-agency-assistant-high
#| tbl-cap: "Top High-Agency Assistant Messages"
#| output: asis

if not agency_messages.empty:
    subset = agency_messages[agency_messages["message_role"] == "assistant"].copy()
    subset = subset.dropna(subset=["agency_score"])
    text_column = "text_translated" if "text_translated" in subset.columns else "text_original"

    top_pos = (
        subset.nlargest(5, "agency_score")
        .loc[:, ["message_id", "agency_score", text_column]]
        .rename(columns={text_column: "message"})
        .copy()
    )

    if not top_pos.empty:
        # Escape special characters that break markdown tables
        top_pos["message"] = top_pos["message"].apply(
            lambda x: str(x).replace("|", "\\|").replace("\n", " ") if pd.notna(x) else ""
        )
        display(Markdown(top_pos.reset_index(drop=True).to_markdown()))
else:
    print("No agency scores available.")
```

```{python}
#| label: tbl-agency-assistant-low
#| tbl-cap: "Lowest Agency Assistant Messages"
#| output: asis

if not agency_messages.empty:
    subset = agency_messages[agency_messages["message_role"] == "assistant"].copy()
    subset = subset.dropna(subset=["agency_score"])
    text_column = "text_translated" if "text_translated" in subset.columns else "text_original"

    top_neg = (
        subset.nsmallest(5, "agency_score")
        .loc[:, ["message_id", "agency_score", text_column]]
        .rename(columns={text_column: "message"})
        .copy()
    )

    if not top_neg.empty:
        # Escape special characters that break markdown tables
        top_neg["message"] = top_neg["message"].apply(
            lambda x: str(x).replace("|", "\\|").replace("\n", " ") if pd.notna(x) else ""
        )
        display(Markdown(top_neg.reset_index(drop=True).to_markdown()))
else:
    print("No agency scores available.")
```

```{python}
#| label: tbl-agency-assistant-neutral
#| tbl-cap: "Neutral Agency Assistant Messages"
#| output: asis

if not agency_messages.empty:
    subset = agency_messages[agency_messages["message_role"] == "assistant"].copy()
    subset = subset.dropna(subset=["agency_score"])
    text_column = "text_translated" if "text_translated" in subset.columns else "text_original"

    neutral_cutoff = 0.15
    neutral_subset = subset[(subset["agency_score"].abs() <= neutral_cutoff)]
    if len(neutral_subset) > 0:
        neutral = neutral_subset.sample(min(5, len(neutral_subset)), random_state=42)
        neutral = neutral.loc[:, ["message_id", "agency_score", text_column]].rename(columns={text_column: "message"}).copy()
        # Escape special characters that break markdown tables
        neutral["message"] = neutral["message"].apply(
            lambda x: str(x).replace("|", "\\|").replace("\n", " ") if pd.notna(x) else ""
        )
        display(Markdown(neutral.reset_index(drop=True).to_markdown()))
    else:
        print("No neutral agency assistant messages found.")
else:
    print("No agency scores available.")
```

By analyzing these patterns over time, educators can identify which topics require enhanced content, where students struggle most, and how to optimize the AI's pedagogical approach.

---

# Summary and Recommendations

This analysis provides comprehensive insights into how students interact with the AI assistant on the Udhyam learning platform. By examining message patterns, sentiment, topics, and engagement dynamics, we have identified key trends that can guide platform improvements and optimize the learning experience.

## Key Insights

```{python}
#| output: asis
# Generate full sentence insights
insights = []

# Message activity insights
if not timeline_daily.empty and not timeline_hourly.empty:
    peak_hour = timeline_hourly.loc[timeline_hourly['messages'].idxmax(), 'hour']
    total_messages = timeline_daily['messages'].sum()
    insights.append(f"**Engagement Volume:** Student engagement is substantial, with a total of {total_messages:,} messages exchanged over the analysis period. Peak activity occurs around hour {peak_hour}, indicating a concentrated window of student engagement that should be considered when scheduling support and platform maintenance.")

# CAL state insights
if not cal_state_counts.empty:
    top_state = cal_state_counts.iloc[0]
    insights.append(f"**Geographic Focus:** The '{top_state['cal_state']}' region is the primary focus of student interactions, generating {top_state['message_count']:,} messages. This high-volume region represents a critical area where students spend most of their time and where the AI assistant provides the most support. Optimizing content and AI responses for this region could yield significant improvements in student outcomes.")

# Sentiment insights
if not sentiment_counts.empty:
    user_sentiments = sentiment_counts[sentiment_counts['role'] == 'user']
    if not user_sentiments.empty:
        dominant_sentiment = user_sentiments.loc[user_sentiments['messages'].idxmax(), 'sentiment_label']
        ai_sentiments = sentiment_counts[sentiment_counts['role'] == 'assistant']
        dominant_ai_sentiment = ai_sentiments.loc[ai_sentiments['messages'].idxmax(), 'sentiment_label'] if not ai_sentiments.empty else "unknown"
        insights.append(f"**Emotional Tone:** Student sentiment is predominantly {dominant_sentiment.lower()}, reflecting their emotional state when interacting with the platform. The AI assistant maintains a {dominant_ai_sentiment.lower()} tone in its responses, demonstrating consistent emotional support. Maintaining or improving this positive interaction dynamic is essential for student satisfaction and engagement.")

# Topic insights
if not topic_keywords.empty:
    user_topics = topic_keywords[topic_keywords['message_role'] == 'user'].sort_values('message_count', ascending=False)
    if not user_topics.empty:
        top_topic = user_topics.iloc[0]
        insights.append(f"**Primary Discussion Areas:** Student discussions are concentrated around specific topics, with '{top_topic['keywords']}' being the most frequently discussed area with {top_topic['message_count']} messages. This concentration indicates clear student interests and pain points that represent opportunities for targeted content development and AI response optimization.")

# Agency insights
if not agency_messages.empty:
    user_agency = agency_messages[agency_messages['message_role'] == 'user'].dropna(subset=['agency_score'])
    assistant_agency = agency_messages[agency_messages['message_role'] == 'assistant'].dropna(subset=['agency_score'])

    if not user_agency.empty and not assistant_agency.empty:
        user_mean_agency = user_agency['agency_score'].mean()
        user_high_pct = (user_agency['agency_score'] >= AGENCY_POS_THRESHOLD).sum() / len(user_agency) * 100
        assistant_mean_agency = assistant_agency['agency_score'].mean()
        assistant_high_pct = (assistant_agency['agency_score'] >= AGENCY_POS_THRESHOLD).sum() / len(assistant_agency) * 100

        insights.append(f"**Agency in Conversations:** Students demonstrate an average agency score of {user_mean_agency:.2f}, with {user_high_pct:.1f}% of messages expressing high-agency language (proactive problem-solving, decision-making, goal-setting). The AI assistant achieves an average agency score of {assistant_mean_agency:.2f}, with {assistant_high_pct:.1f}% of responses employing empowering language that encourages student initiative. This balance indicates the platform is effectively fostering student autonomy and self-directed learning, which are critical factors for long-term engagement and skill development.")

for insight in insights:
    if insight:
        print(f"{insight}\n\n")
```

## Recommendations and Action Items

...

## Next Steps

...

---

```{python}
#| output: asis
print(f"**Report generated:** {pd.Timestamp.today().strftime('%B %d, %Y')}")
print(f"\n**Analysis period:** {datetime_overview.get('start_datetime', 'N/A')} to {datetime_overview.get('end_datetime', 'N/A')}")
print(f"\n**Total messages analyzed:** {datetime_overview.get('total_messages', 'N/A'):,}")
```
